{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7f4200-fbef-4dc0-acda-822d9c434785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#please install scipy and pandas by:\n",
    "# %pip install scipy\n",
    "# %pip install pandas\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import stft\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fbfc368-777c-430f-9231-e798938d70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\shadow\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\shadow\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scipy) (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25affbe9-2838-4b23-b110-c815615ca080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def wav2fft(Path):\n",
    "    # Load an audio file\n",
    "    file_path = Path  # Replace with the path to your audio file\n",
    "    sr, y = wavfile.read(file_path)\n",
    "\n",
    "    # Compute the STFT\n",
    "    n_fft = 2048  # Number of FFT points (window size)\n",
    "    hop_length = 512  # Hop length between frames\n",
    "    f, t, Zxx = stft(y, fs=sr, nperseg=n_fft, noverlap=hop_length)\n",
    "\n",
    "    # Convert amplitude spectrogram to dB scale\n",
    "    Zxx_db = 10 * np.log10(np.abs(Zxx)+0.0001)\n",
    "    return Zxx_db\n",
    "\n",
    "def data2fft(y):\n",
    "    # Compute the STFT\n",
    "    n_fft = 2048  # Number of FFT points (window size)\n",
    "    hop_length = 512  # Hop length between frames\n",
    "    f, t, Zxx = stft(y, fs=8000, nperseg=n_fft, noverlap=hop_length)\n",
    "\n",
    "    # Convert amplitude spectrogram to dB scale\n",
    "    Zxx_db = 10 * np.log10(np.abs(Zxx)+0.0001)\n",
    "    return Zxx_db\n",
    "\n",
    "\n",
    "##\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def cost_function_reg(X, y, weights, lambda_reg):\n",
    "    m = X.shape[0]\n",
    "    h = sigmoid(X @ weights)\n",
    "    epsilon = 1e-5\n",
    "    reg_term = (lambda_reg / (2 * m)) * np.sum(np.square(weights[1:]))\n",
    "    cost = -1/m * np.sum(y * np.log(h + epsilon) + (1 - y) * np.log(1 - h + epsilon)) + reg_term\n",
    "    return cost\n",
    "\n",
    "def gradient_descent_reg(X, y, weights, learning_rate, iterations, lambda_reg):\n",
    "    m = X.shape[0]\n",
    "    cost_history = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        weights[0] -= (learning_rate / m) * np.sum(sigmoid(X @ weights) - y)\n",
    "        weights[1:] -= (learning_rate / m) * (X[:, 1:].T @ (sigmoid(X @ weights) - y) + lambda_reg * weights[1:])\n",
    "        cost_history.append(cost_function_reg(X, y, weights, lambda_reg))\n",
    "\n",
    "    return weights, cost_history\n",
    "\n",
    "def train_one_vs_rest(X, y, num_classes, learning_rate, iterations, lambda_reg):\n",
    "    models = []\n",
    "    m, n = X.shape\n",
    "    X = np.hstack((np.ones((m, 1)), X))\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        y_ovr = np.where(y == i, 1, 0)\n",
    "        weights = np.zeros(n + 1)\n",
    "        weights, _ = gradient_descent_reg(X, y_ovr, weights, learning_rate, iterations, lambda_reg)\n",
    "        models.append(weights)\n",
    "\n",
    "    return models\n",
    "\n",
    "def predict(X, models):\n",
    "    m = X.shape[0]\n",
    "    X = np.hstack((np.ones((m, 1)), X))\n",
    "    preds = np.array([sigmoid(X @ w) for w in models]).T\n",
    "    return np.argmax(preds, axis=1)\n",
    "\n",
    "# Manual Data Splitting Function\n",
    "def split_data(data, train_frac, test_frac):\n",
    "    train_size = int(len(data) * train_frac)\n",
    "    test_size = int(len(data) * test_frac)\n",
    "    train_data = data[:train_size]\n",
    "    validation_data = data[train_size:train_size + test_size]\n",
    "    test_data = data[train_size + test_size:]\n",
    "    return train_data, validation_data, test_data\n",
    "\n",
    "# Manual Feature Scaling Function\n",
    "def standardize_data(X):\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "    return (X - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbae0f7-c41b-45ed-8b00-507c43a5ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9458858413639734\n",
      "Test Accuracy: 0.9459659511472983\n"
     ]
    }
   ],
   "source": [
    "# Train and test classifier\n",
    "v1=wav2fft(\"./ENGR_518_group_14_datasets/wav1.wav\")[0:150,1:3000].transpose()\n",
    "v2=wav2fft(\"./ENGR_518_group_14_datasets/wav2.wav\")[0:150,1:3000].transpose()\n",
    "v3=wav2fft(\"./ENGR_518_group_14_datasets/wav3.wav\")[0:150,1:3000].transpose()\n",
    "\n",
    "\n",
    "data = []\n",
    "df = pd.DataFrame.from_records(v1)\n",
    "df['label'] = 0\n",
    "data.append(df)\n",
    "df = pd.DataFrame.from_records(v2)\n",
    "df['label'] = 1\n",
    "data.append(df)\n",
    "df = pd.DataFrame.from_records(v3)\n",
    "df['label'] = 2\n",
    "data.append(df)\n",
    "\n",
    "data = pd.concat(data, ignore_index=True)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Splitting Data\n",
    "train_data, validation_data, test_data = split_data(data, 0.7, 0.15)\n",
    "X_train, y_train = train_data.drop('label', axis=1), train_data['label']\n",
    "X_val, y_val = validation_data.drop('label', axis=1), validation_data['label']\n",
    "X_test, y_test = test_data.drop('label', axis=1), test_data['label']\n",
    "\n",
    "# Feature Scaling\n",
    "#X_train_scaled= standardize_data(X_train)\n",
    "#X_val_scaled= standardize_data(X_val)\n",
    "#X_test_scaled= standardize_data(X_test)\n",
    "X_train_scaled= (X_train)\n",
    "X_val_scaled= (X_val)\n",
    "X_test_scaled= (X_test)\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.01\n",
    "iterations = 3000\n",
    "num_classes = 3\n",
    "lambda_reg = 0.1\n",
    "\n",
    "# Training the Models\n",
    "models_reg = train_one_vs_rest(X_train_scaled, y_train, num_classes, learning_rate, iterations, lambda_reg)\n",
    "\n",
    "np.save(\"subject1.weight150\",models_reg[0])\n",
    "np.save(\"subject2.weight150\",models_reg[1])\n",
    "np.save(\"subject3.weight150\",models_reg[2])\n",
    "\n",
    "# Validation and Testing\n",
    "y_val_pred_reg = predict(X_val_scaled, models_reg)\n",
    "accuracy_val = np.mean(y_val_pred_reg == y_val)\n",
    "\n",
    "y_test_pred = predict(X_test_scaled, models_reg)\n",
    "accuracy_test = np.mean(y_test_pred == y_test)\n",
    "\n",
    "# Print the accuracy results\n",
    "print(f\"Validation Accuracy: {accuracy_val}\")\n",
    "print(f\"Test Accuracy: {accuracy_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad3bf27-8b3e-4ff7-935e-0ce7fca91b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lamba:\t262144\tValidation Accuracy:\t0.31653076352853965\tTest Accuracy:\t0.3168023686158401\n",
      "Lamba:\t262144\tValidation Accuracy:\t0.4618235730170497\tTest Accuracy:\t0.47964470762398226\n",
      "Lamba:\t262144\tValidation Accuracy:\t0.3313565604151223\tTest Accuracy:\t0.3449296817172465\n",
      "Lamba:\t262144\tValidation Accuracy:\t0.33209785025945143\tTest Accuracy:\t0.35899333826794966\n",
      "Lamba:\t262144\tValidation Accuracy:\t0.3157894736842105\tTest Accuracy:\t0.33530717986676534\n",
      "Lamba:\t262144\tValidation Accuracy:\t0.30911786508524836\tTest Accuracy:\t0.34863064396743154\n",
      "Lamba:\t262144\tValidation Accuracy:\t0.33432171979243885\tTest Accuracy:\t0.35899333826794966\n",
      "Lamba:\t262144\tValidation Accuracy:\t0.3617494440326168\tTest Accuracy:\t0.3441894892672095\n",
      "Lamba:\t262144\tValidation Accuracy:\t0.32765011119347665\tTest Accuracy:\t0.33974833456698744\n",
      "Lamba:\t262144\tValidation Accuracy:\t0.34840622683469236\tTest Accuracy:\t0.33530717986676534\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.4032616753150482\tTest Accuracy:\t0.42116950407105846\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.513713862120089\tTest Accuracy:\t0.5122131754256106\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.3157894736842105\tTest Accuracy:\t0.35529237601776464\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.3291326908821349\tTest Accuracy:\t0.3153219837157661\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.44551519644180876\tTest Accuracy:\t0.4552183567727609\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.33209785025945143\tTest Accuracy:\t0.3441894892672095\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.38917716827279464\tTest Accuracy:\t0.3560325684678016\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.39140103780578206\tTest Accuracy:\t0.4256106587712805\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.3306152705707932\tTest Accuracy:\t0.3249444855662472\n",
      "Lamba:\t131072.0\tValidation Accuracy:\t0.34840622683469236\tTest Accuracy:\t0.3316062176165803\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.35656041512231285\tTest Accuracy:\t0.3323464100666173\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.3424759080800593\tTest Accuracy:\t0.33678756476683935\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.33432171979243885\tTest Accuracy:\t0.35529237601776464\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.6300963676797627\tTest Accuracy:\t0.6306439674315322\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.469236471460341\tTest Accuracy:\t0.42635085122131755\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.3380281690140845\tTest Accuracy:\t0.35751295336787564\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.335063009636768\tTest Accuracy:\t0.33974833456698744\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.43736100815418827\tTest Accuracy:\t0.4293116210214656\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.35285396590066714\tTest Accuracy:\t0.3153219837157661\n",
      "Lamba:\t65536.0\tValidation Accuracy:\t0.6130467012601928\tTest Accuracy:\t0.6232420429311621\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.5722757598220904\tTest Accuracy:\t0.5780903034789046\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.3446997776130467\tTest Accuracy:\t0.3404885270170244\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.558932542624166\tTest Accuracy:\t0.5655070318282753\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.6345441067457376\tTest Accuracy:\t0.6299037749814952\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.3684210526315789\tTest Accuracy:\t0.40340488527017027\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.3543365455893254\tTest Accuracy:\t0.3456698741672835\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.3587842846553002\tTest Accuracy:\t0.40414507772020725\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.3587842846553002\tTest Accuracy:\t0.34863064396743154\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.47220163083765754\tTest Accuracy:\t0.43671354552183567\n",
      "Lamba:\t32768.0\tValidation Accuracy:\t0.36916234247590807\tTest Accuracy:\t0.3774981495188749\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.48332097850259453\tTest Accuracy:\t0.47520355292376015\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.6827279466271312\tTest Accuracy:\t0.6780162842339008\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.4877687175685693\tTest Accuracy:\t0.5055514433752776\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.5381764269829503\tTest Accuracy:\t0.5233160621761658\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.5233506300963677\tTest Accuracy:\t0.5136935603256847\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.3602668643439585\tTest Accuracy:\t0.33974833456698744\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.787991104521868\tTest Accuracy:\t0.7757216876387861\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.37212750185322463\tTest Accuracy:\t0.36565507031828276\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.6716085989621943\tTest Accuracy:\t0.6698741672834937\n",
      "Lamba:\t16384.0\tValidation Accuracy:\t0.4284655300222387\tTest Accuracy:\t0.4048852701702443\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.7412898443291327\tTest Accuracy:\t0.771280532938564\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.46627131208302447\tTest Accuracy:\t0.4789045151739452\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.83765752409192\tTest Accuracy:\t0.8401184307920059\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.6738324684951816\tTest Accuracy:\t0.6728349370836417\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.6471460340993328\tTest Accuracy:\t0.6313841598815693\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.6812453669384729\tTest Accuracy:\t0.6831976313841599\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.5833951074870274\tTest Accuracy:\t0.5973353071798667\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.6197183098591549\tTest Accuracy:\t0.6299037749814952\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.4306893995552261\tTest Accuracy:\t0.40340488527017027\n",
      "Lamba:\t8192.0\tValidation Accuracy:\t0.41660489251297256\tTest Accuracy:\t0.4219096965210955\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.609340252038547\tTest Accuracy:\t0.6113989637305699\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.5819125277983692\tTest Accuracy:\t0.5692079940784603\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.9117865085248332\tTest Accuracy:\t0.9059955588452998\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.9295774647887324\tTest Accuracy:\t0.9104367135455218\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.8813936249073387\tTest Accuracy:\t0.8808290155440415\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.4477390659747961\tTest Accuracy:\t0.4396743153219837\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.8295033358042995\tTest Accuracy:\t0.8490007401924501\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.9266123054114158\tTest Accuracy:\t0.924500370096225\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.8124536693847294\tTest Accuracy:\t0.7905255366395263\n",
      "Lamba:\t4096.0\tValidation Accuracy:\t0.816160118606375\tTest Accuracy:\t0.8127313101406366\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.9065974796145293\tTest Accuracy:\t0.9141376757957069\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.9251297257227576\tTest Accuracy:\t0.9193190229459659\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.44106745737583397\tTest Accuracy:\t0.4233900814211695\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.9258710155670867\tTest Accuracy:\t0.9370836417468542\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.8524833209785025\tTest Accuracy:\t0.8630643967431533\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.6612305411415864\tTest Accuracy:\t0.6447076239822354\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.933283914010378\tTest Accuracy:\t0.9296817172464841\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.5581912527798369\tTest Accuracy:\t0.5803108808290155\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.9303187546330616\tTest Accuracy:\t0.9296817172464841\n",
      "Lamba:\t2048.0\tValidation Accuracy:\t0.8591549295774648\tTest Accuracy:\t0.8682457438934122\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.69236471460341\tTest Accuracy:\t0.6809770540340488\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.9310600444773907\tTest Accuracy:\t0.9282013323464101\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.6627131208302446\tTest Accuracy:\t0.6661732050333087\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.7887323943661971\tTest Accuracy:\t0.7838638045891931\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.933283914010378\tTest Accuracy:\t0.9289415247964471\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.9303187546330616\tTest Accuracy:\t0.930421909696521\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.9258710155670867\tTest Accuracy:\t0.926720947446336\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.9399555226093402\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.7538917716827279\tTest Accuracy:\t0.7660991857883049\n",
      "Lamba:\t1024.0\tValidation Accuracy:\t0.9347664936990363\tTest Accuracy:\t0.9289415247964471\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.9444032616753151\tTest Accuracy:\t0.9319022945965951\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.9414381022979985\tTest Accuracy:\t0.9356032568467801\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.9369903632320237\tTest Accuracy:\t0.9385640266469282\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.933283914010378\tTest Accuracy:\t0.9296817172464841\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.9347664936990363\tTest Accuracy:\t0.9452257586972613\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.8687916975537435\tTest Accuracy:\t0.840858623242043\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.9258710155670867\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.7783543365455893\tTest Accuracy:\t0.7794226498889711\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.6686434395848777\tTest Accuracy:\t0.6558105107327905\n",
      "Lamba:\t512.0\tValidation Accuracy:\t0.6671608598962194\tTest Accuracy:\t0.6558105107327905\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.9362490733876946\tTest Accuracy:\t0.9511472982975574\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.9503335804299481\tTest Accuracy:\t0.9415247964470762\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.9414381022979985\tTest Accuracy:\t0.9356032568467801\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.9325426241660489\tTest Accuracy:\t0.9385640266469282\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.933283914010378\tTest Accuracy:\t0.9430051813471503\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.9318013343217197\tTest Accuracy:\t0.9459659511472983\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.9392142327650111\tTest Accuracy:\t0.9311621021465581\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.7442550037064493\tTest Accuracy:\t0.7231680236861584\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.9318013343217197\tTest Accuracy:\t0.9393042190969653\n",
      "Lamba:\t256.0\tValidation Accuracy:\t0.955522609340252\tTest Accuracy:\t0.9459659511472983\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.9377316530763529\tTest Accuracy:\t0.9444855662472242\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.9473684210526315\tTest Accuracy:\t0.9452257586972613\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.9310600444773907\tTest Accuracy:\t0.9467061435973353\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.8406226834692365\tTest Accuracy:\t0.847520355292376\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.9436619718309859\tTest Accuracy:\t0.9430051813471503\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.9451445515196442\tTest Accuracy:\t0.9489267209474463\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.7620459599703484\tTest Accuracy:\t0.7794226498889711\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.9444032616753151\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.9481097108969607\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t128.0\tValidation Accuracy:\t0.9280948851000741\tTest Accuracy:\t0.9333826794966691\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.9303187546330616\tTest Accuracy:\t0.9548482605477424\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.9340252038547072\tTest Accuracy:\t0.9444855662472242\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9496669133974833\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.9362490733876946\tTest Accuracy:\t0.9474463360473723\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.8339510748702743\tTest Accuracy:\t0.8393782383419689\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.9518161601186064\tTest Accuracy:\t0.9385640266469282\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.9488510007412898\tTest Accuracy:\t0.9415247964470762\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.9369903632320237\tTest Accuracy:\t0.9415247964470762\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.9481097108969607\tTest Accuracy:\t0.9496669133974833\n",
      "Lamba:\t64.0\tValidation Accuracy:\t0.8421052631578947\tTest Accuracy:\t0.8312361213915618\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.9444032616753151\tTest Accuracy:\t0.9415247964470762\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.9362490733876946\tTest Accuracy:\t0.9319022945965951\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.9458858413639734\tTest Accuracy:\t0.9437453737971873\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.9392142327650111\tTest Accuracy:\t0.9341228719467062\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.9458858413639734\tTest Accuracy:\t0.9467061435973353\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.9473684210526315\tTest Accuracy:\t0.9415247964470762\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.9377316530763529\tTest Accuracy:\t0.9407846039970392\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.9466271312083024\tTest Accuracy:\t0.9378238341968912\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.949592290585619\tTest Accuracy:\t0.9518874907475944\n",
      "Lamba:\t32.0\tValidation Accuracy:\t0.9414381022979985\tTest Accuracy:\t0.9393042190969653\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9393042190969653\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.9473684210526315\tTest Accuracy:\t0.9481865284974094\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.9510748702742773\tTest Accuracy:\t0.9430051813471503\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.9473684210526315\tTest Accuracy:\t0.9452257586972613\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.9532987398072647\tTest Accuracy:\t0.9348630643967432\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.9362490733876946\tTest Accuracy:\t0.9496669133974833\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.9429206819866568\tTest Accuracy:\t0.9481865284974094\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.5552260934025204\tTest Accuracy:\t0.5521835677276091\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9348630643967432\n",
      "Lamba:\t16.0\tValidation Accuracy:\t0.720533728687917\tTest Accuracy:\t0.6994818652849741\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.938472942920682\tTest Accuracy:\t0.9459659511472983\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.9392142327650111\tTest Accuracy:\t0.9333826794966691\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.9318013343217197\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.6968124536693847\tTest Accuracy:\t0.7068837897853442\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.9399555226093402\tTest Accuracy:\t0.9400444115470022\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.9481097108969607\tTest Accuracy:\t0.9378238341968912\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.9429206819866568\tTest Accuracy:\t0.9511472982975574\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.938472942920682\tTest Accuracy:\t0.9481865284974094\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.9355077835433655\tTest Accuracy:\t0.9378238341968912\n",
      "Lamba:\t8.0\tValidation Accuracy:\t0.8836174944403261\tTest Accuracy:\t0.8941524796447077\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.9451445515196442\tTest Accuracy:\t0.9452257586972613\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.938472942920682\tTest Accuracy:\t0.9467061435973353\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.938472942920682\tTest Accuracy:\t0.9378238341968912\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.9414381022979985\tTest Accuracy:\t0.9415247964470762\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9356032568467801\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.9421793921423276\tTest Accuracy:\t0.9504071058475203\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.9458858413639734\tTest Accuracy:\t0.9444855662472242\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.7546330615270571\tTest Accuracy:\t0.774981495188749\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.9421793921423276\tTest Accuracy:\t0.9400444115470022\n",
      "Lamba:\t4.0\tValidation Accuracy:\t0.9421793921423276\tTest Accuracy:\t0.9504071058475203\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.9473684210526315\tTest Accuracy:\t0.9407846039970392\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.9540400296515937\tTest Accuracy:\t0.9452257586972613\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.949592290585619\tTest Accuracy:\t0.9430051813471503\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.9414381022979985\tTest Accuracy:\t0.9444855662472242\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.9325426241660489\tTest Accuracy:\t0.9459659511472983\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.8458117123795404\tTest Accuracy:\t0.8430792005921539\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.9392142327650111\tTest Accuracy:\t0.9348630643967432\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.7116382505559674\tTest Accuracy:\t0.7157660991857883\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.920059215396003\n",
      "Lamba:\t2.0\tValidation Accuracy:\t0.938472942920682\tTest Accuracy:\t0.9452257586972613\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.9399555226093402\tTest Accuracy:\t0.9526276831976314\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.8050407709414381\tTest Accuracy:\t0.8016284233900814\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.9481097108969607\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.9444032616753151\tTest Accuracy:\t0.9430051813471503\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.9421793921423276\tTest Accuracy:\t0.9400444115470022\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.9355077835433655\tTest Accuracy:\t0.9459659511472983\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.9362490733876946\tTest Accuracy:\t0.9370836417468542\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.9318013343217197\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.9444032616753151\tTest Accuracy:\t0.9526276831976314\n",
      "Lamba:\t1.0\tValidation Accuracy:\t0.9436619718309859\tTest Accuracy:\t0.9511472982975574\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.8020756115641215\tTest Accuracy:\t0.8245743893412287\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.9444032616753151\tTest Accuracy:\t0.9444855662472242\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.8117123795404003\tTest Accuracy:\t0.8105107327905255\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.933283914010378\tTest Accuracy:\t0.9430051813471503\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.9377316530763529\tTest Accuracy:\t0.9407846039970392\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.9473684210526315\tTest Accuracy:\t0.9437453737971873\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.9392142327650111\tTest Accuracy:\t0.9385640266469282\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.9421793921423276\tTest Accuracy:\t0.9467061435973353\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.9362490733876946\tTest Accuracy:\t0.9474463360473723\n",
      "Lamba:\t0.5\tValidation Accuracy:\t0.9436619718309859\tTest Accuracy:\t0.9526276831976314\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.9377316530763529\tTest Accuracy:\t0.9541080680977054\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.9318013343217197\tTest Accuracy:\t0.9378238341968912\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.938472942920682\tTest Accuracy:\t0.9430051813471503\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.9414381022979985\tTest Accuracy:\t0.9481865284974094\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.9458858413639734\tTest Accuracy:\t0.9430051813471503\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.9451445515196442\tTest Accuracy:\t0.9459659511472983\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.9347664936990363\tTest Accuracy:\t0.9533678756476683\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9444855662472242\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.9510748702742773\tTest Accuracy:\t0.9481865284974094\n",
      "Lamba:\t0.25\tValidation Accuracy:\t0.7694588584136397\tTest Accuracy:\t0.7698001480384901\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.72646404744255\tTest Accuracy:\t0.7483345669874167\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.9303187546330616\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.8472942920681986\tTest Accuracy:\t0.8638045891931903\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.6708673091178651\tTest Accuracy:\t0.6728349370836417\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.9362490733876946\tTest Accuracy:\t0.9348630643967432\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.9392142327650111\tTest Accuracy:\t0.9467061435973353\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.9310600444773907\tTest Accuracy:\t0.9407846039970392\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.9458858413639734\tTest Accuracy:\t0.9548482605477424\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.9458858413639734\tTest Accuracy:\t0.9378238341968912\n",
      "Lamba:\t0.125\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.7590808005930318\tTest Accuracy:\t0.7490747594374537\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.9473684210526315\tTest Accuracy:\t0.9363434492968171\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.9340252038547072\tTest Accuracy:\t0.9378238341968912\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.9347664936990363\tTest Accuracy:\t0.9370836417468542\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.9451445515196442\tTest Accuracy:\t0.9496669133974833\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9555884529977794\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.9303187546330616\tTest Accuracy:\t0.9437453737971873\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.9577464788732394\tTest Accuracy:\t0.9415247964470762\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.9399555226093402\tTest Accuracy:\t0.9437453737971873\n",
      "Lamba:\t0.0625\tValidation Accuracy:\t0.9429206819866568\tTest Accuracy:\t0.9481865284974094\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.9199406968124537\tTest Accuracy:\t0.9319022945965951\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.938472942920682\tTest Accuracy:\t0.9393042190969653\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.9444032616753151\tTest Accuracy:\t0.9356032568467801\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.9303187546330616\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.9444032616753151\tTest Accuracy:\t0.9437453737971873\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9437453737971873\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.9362490733876946\tTest Accuracy:\t0.9385640266469282\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.9392142327650111\tTest Accuracy:\t0.9467061435973353\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.9421793921423276\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t0.03125\tValidation Accuracy:\t0.9429206819866568\tTest Accuracy:\t0.9422649888971133\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.9377316530763529\tTest Accuracy:\t0.9548482605477424\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.7108969607116382\tTest Accuracy:\t0.7031828275351591\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.8776871756856931\tTest Accuracy:\t0.8667653589933383\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.9214232765011119\tTest Accuracy:\t0.9111769059955589\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.9036323202372127\tTest Accuracy:\t0.9089563286454478\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.9466271312083024\tTest Accuracy:\t0.9474463360473723\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.955522609340252\tTest Accuracy:\t0.9385640266469282\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.9473684210526315\tTest Accuracy:\t0.9481865284974094\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.949592290585619\tTest Accuracy:\t0.9393042190969653\n",
      "Lamba:\t0.015625\tValidation Accuracy:\t0.9377316530763529\tTest Accuracy:\t0.9356032568467801\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.9473684210526315\tTest Accuracy:\t0.9430051813471503\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.9392142327650111\tTest Accuracy:\t0.9393042190969653\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.9525574499629355\tTest Accuracy:\t0.9400444115470022\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.832468495181616\tTest Accuracy:\t0.8497409326424871\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.9295774647887324\tTest Accuracy:\t0.927461139896373\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.9451445515196442\tTest Accuracy:\t0.9533678756476683\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.949592290585619\tTest Accuracy:\t0.9393042190969653\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.9584877687175686\tTest Accuracy:\t0.9363434492968171\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.9377316530763529\tTest Accuracy:\t0.9563286454478165\n",
      "Lamba:\t0.0078125\tValidation Accuracy:\t0.83765752409192\tTest Accuracy:\t0.8615840118430792\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.7249814677538917\tTest Accuracy:\t0.7327905255366395\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.9355077835433655\tTest Accuracy:\t0.9407846039970392\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.9414381022979985\tTest Accuracy:\t0.9444855662472242\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.9421793921423276\tTest Accuracy:\t0.9400444115470022\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.949592290585619\tTest Accuracy:\t0.9319022945965951\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.9421793921423276\tTest Accuracy:\t0.9518874907475944\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9474463360473723\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.9436619718309859\tTest Accuracy:\t0.9356032568467801\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.9429206819866568\tTest Accuracy:\t0.9385640266469282\n",
      "Lamba:\t0.00390625\tValidation Accuracy:\t0.9510748702742773\tTest Accuracy:\t0.9363434492968171\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.9444032616753151\tTest Accuracy:\t0.924500370096225\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9533678756476683\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.9406968124536694\tTest Accuracy:\t0.9437453737971873\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.9392142327650111\tTest Accuracy:\t0.9467061435973353\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.9436619718309859\tTest Accuracy:\t0.9496669133974833\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.8554484803558191\tTest Accuracy:\t0.8586232420429312\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.9355077835433655\tTest Accuracy:\t0.9437453737971873\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.9414381022979985\tTest Accuracy:\t0.927461139896373\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.9421793921423276\tTest Accuracy:\t0.9415247964470762\n",
      "Lamba:\t0.001953125\tValidation Accuracy:\t0.9362490733876946\tTest Accuracy:\t0.9533678756476683\n"
     ]
    }
   ],
   "source": [
    "## Boosting, this loops will take a long time\n",
    "# go get a cup of coffee while it is running, or maybe two\n",
    "\n",
    "lambda_reg = 2**18\n",
    "ind=1\n",
    "while lambda_reg>0.001:\n",
    "\n",
    "\n",
    "    # Training the Models\n",
    "    for repeats in range(0,10):\n",
    "        data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # Splitting Data\n",
    "        train_data, validation_data, test_data = split_data(data, 0.7, 0.15)\n",
    "        X_train, y_train = train_data.drop('label', axis=1), train_data['label']\n",
    "        X_val, y_val = validation_data.drop('label', axis=1), validation_data['label']\n",
    "        X_test, y_test = test_data.drop('label', axis=1), test_data['label']\n",
    "\n",
    "        X_train_scaled = (X_train)\n",
    "        X_val_scaled = (X_val)\n",
    "        X_test_scaled = (X_test)\n",
    "\n",
    "        models_reg = train_one_vs_rest(X_train_scaled, y_train, num_classes, learning_rate, iterations, lambda_reg)\n",
    "\n",
    "        # Validation and Testing\n",
    "        y_val_pred_reg = predict(X_val_scaled, models_reg)\n",
    "        accuracy_val = np.mean(y_val_pred_reg == y_val)\n",
    "\n",
    "        y_test_pred = predict(X_test_scaled, models_reg)\n",
    "        accuracy_test = np.mean(y_test_pred == y_test)\n",
    "\n",
    "        # Print the accuracy results\n",
    "        print(f\"Lamba:\\t{lambda_reg}\\tValidation Accuracy:\\t{accuracy_val}\\tTest Accuracy:\\t{accuracy_test}\")\n",
    "\n",
    "        pd.DataFrame.from_records(models_reg).to_csv(\"./ENGR_518_group_14_datasets/boosting/boost_%03d_%03d.csv\"%(ind,repeats), header=False, index=False)\n",
    "    lambda_reg/=2\n",
    "    ind+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1314bd8-a43a-40d8-94f9-9a0c70d823c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8176426982950333\n",
      "Test Accuracy: 0.8105107327905255\n"
     ]
    }
   ],
   "source": [
    "selectFreq=[2,5,7,8,12,15]\n",
    "# Load Data\n",
    "v1=wav2fft(\"./ENGR_518_group_14_datasets/wav1.wav\")[selectFreq,1:3000].transpose()\n",
    "v2=wav2fft(\"./ENGR_518_group_14_datasets/wav2.wav\")[selectFreq,1:3000].transpose()\n",
    "v3=wav2fft(\"./ENGR_518_group_14_datasets/wav3.wav\")[selectFreq,1:3000].transpose()\n",
    "\n",
    "data = []\n",
    "df = pd.DataFrame.from_records(v1)\n",
    "df['label'] = 0\n",
    "data.append(df)\n",
    "df = pd.DataFrame.from_records(v2)\n",
    "df['label'] = 1\n",
    "data.append(df)\n",
    "df = pd.DataFrame.from_records(v3)\n",
    "df['label'] = 2\n",
    "data.append(df)\n",
    "\n",
    "data = pd.concat(data, ignore_index=True)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Splitting Data\n",
    "train_data, validation_data, test_data = split_data(data, 0.7, 0.15)\n",
    "X_train, y_train = train_data.drop('label', axis=1), train_data['label']\n",
    "X_val, y_val = validation_data.drop('label', axis=1), validation_data['label']\n",
    "X_test, y_test = test_data.drop('label', axis=1), test_data['label']\n",
    "\n",
    "# Feature Scaling\n",
    "#X_train_scaled= standardize_data(X_train)\n",
    "#X_val_scaled= standardize_data(X_val)\n",
    "#X_test_scaled= standardize_data(X_test)\n",
    "X_train_scaled= (X_train)\n",
    "X_val_scaled= (X_val)\n",
    "X_test_scaled= (X_test)\n",
    "\n",
    "# Training Parameters\n",
    "learning_rate = 0.01\n",
    "iterations = 3000\n",
    "num_classes = 3\n",
    "lambda_reg = 0.1\n",
    "\n",
    "# Training the Models\n",
    "models_reg = train_one_vs_rest(X_train_scaled, y_train, num_classes, learning_rate, iterations, lambda_reg)\n",
    "\n",
    "# Validation and Testing\n",
    "y_val_pred_reg = predict(X_val_scaled, models_reg)\n",
    "accuracy_val = np.mean(y_val_pred_reg == y_val)\n",
    "\n",
    "y_test_pred = predict(X_test_scaled, models_reg)\n",
    "accuracy_test = np.mean(y_test_pred == y_test)\n",
    "\n",
    "# Print the accuracy results\n",
    "print(f\"Validation Accuracy: {accuracy_val}\")\n",
    "print(f\"Test Accuracy: {accuracy_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed813b-8597-4976-8dbb-80a62c70a3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
